import os
import sys
from contextlib import AsyncExitStack
import asyncio

from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage
from langgraph.graph import StateGraph,MessagesState,START,END
from langgraph.prebuilt import ToolNode

from config import OPENAI_API_KEY,AMAP_MAPS_API_KEY
from m10_mcp_basics.agent_stream import run_agent_with_streaming
from m10_mcp_basics.mcp_client import MCPClient
from m10_mcp_basics.mcp_bridge import LangChainMCPAdapter



# ===ç¯å¢ƒé…ç½®===
# ç¯å¢ƒå…¼å®¹
COMMAND = "npx.cmd" if sys.platform == "win32" else "npx"
# å¤åˆ¶å½“å‰pyè¿›ç¨‹çš„ç¯å¢ƒå˜é‡,å¹¶åœ¨å¤åˆ¶çš„ç¯å¢ƒå˜é‡é‡Œæ–°å¢ä¸€æ¡ï¼Œç¡®ä¿å®‰å…¨å¯æ§
env_vars = os.environ.copy()
env_vars["AMAP_MAPS_API_KEY"] = AMAP_MAPS_API_KEY

MCP_SERVER_CONFIGS = [
    {
        "name":"é«˜å¾·åœ°å›¾", # æ‰“å°ä½¿ç”¨äº†ä»€ä¹ˆMCPï¼Œå¯ç§»é™¤
        "command":COMMAND,
        "args":["-y", "@amap/amap-maps-mcp-server"],
        "env":env_vars
    }
    # {...}  ä¹‹åMCPå·¥å…·å¯éšéœ€æ±‚æ‰©å±•å¢åŠ 
]

# ===æ„å»ºå›¾é€»è¾‘===
def build_graph(available_tools):
    """
    è¿™ä¸ªå‡½æ•°åªè®¤toolsåˆ—è¡¨ï¼Œä¸å…³å¿ƒtoolsçš„æ¥æº
    """
    if not available_tools:
        print('âš ï¸ å½“å‰æ²¡æœ‰æ³¨å…¥ä»»ä½•å·¥å…·ï¼ŒAgentå°†ä»…é LLMå›ç­”ã€‚')
    llm = ChatOpenAI(
        model="deepseek-chat",
        api_key=OPENAI_API_KEY,
        base_url="https://api.deepseek.com",
        streaming=True
    )
    # å¦‚æœæ²¡å·¥å…·ï¼Œbind_tools ä¼šè¢«å¿½ç•¥æˆ–å¤„ç†ï¼ŒLangGraphåŒæ ·èƒ½æ­£å¸¸è·‘çº¯å¯¹è¯
    llm_with_tools = llm.bind_tools(available_tools) if available_tools else llm


    sys_prompt = """
    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åœ°ç†ä½ç½®æœåŠ¡åŠ©æ‰‹ã€‚
    1. å½“ç”¨æˆ·æŸ¥è¯¢æ¨¡ç³Šåœ°ç‚¹ï¼ˆå¦‚"è¥¿ç«™"ï¼‰æ—¶ï¼Œä¼šä¼˜å…ˆä½¿ç”¨ç›¸å…³å·¥å…·è·å–å…·ä½“ç»çº¬åº¦æˆ–æ ‡å‡†åç§°ã€‚
    2. å¦‚æœç”¨æˆ·æŸ¥è¯¢"é™„è¿‘"çš„åº—é“ºï¼Œè¯·å…ˆç¡®å®šä¸­å¿ƒç‚¹çš„åæ ‡æˆ–å…·ä½“ä½ç½®ï¼Œå†è¿›è¡Œæœç´¢ã€‚
    3. è°ƒç”¨å·¥å…·æ—¶ï¼Œå‚æ•°è¦å°½å¯èƒ½ç²¾ç¡®ã€‚
    """

    async def agent_node(state:MessagesState):
        messages = [SystemMessage(content=sys_prompt)] + state["messages"]
        # ainvoke:å¼‚æ­¥è°ƒç”¨ç‰ˆçš„invoke
        return {"messages":[await llm_with_tools.ainvoke(messages)]}

    workflow = StateGraph(MessagesState)
    workflow.add_node("agent",agent_node)

    # åŠ¨æ€é€»è¾‘ï¼šå¦‚æœæœ‰å·¥å…·æ‰åŠ å·¥å…·èŠ‚ç‚¹ï¼Œå¦åˆ™å°±æ˜¯çº¯å¯¹è¯
    if available_tools:
        tool_node = ToolNode(available_tools)
        workflow.add_node("tools",tool_node)

        def should_continue(state:MessagesState):
            last_msg = state["messages"][-1]
            if hasattr(last_msg,"tool_calls") and last_msg.tool_calls:
                return "tools"
            return END

        workflow.add_edge(START,"agent")
        workflow.add_conditional_edges("agent",should_continue,{"tools":"tools",END:END})
        workflow.add_edge("tools","agent")
    else:
        workflow.add_edge(START,"agent")
        workflow.add_edge("agent",END)

    return workflow.compile()


# ===MCPå·¥å…·æ‰¹é‡åˆå§‹åŒ–===
async def load_mcp_tools(stack:AsyncExitStack,configs:list):
    """
    è´Ÿè´£éå†é…ç½®ï¼Œæ‰¹é‡å»ºç«‹è¿æ¥ï¼Œæ”¶é›†æ‰€æœ‰å·¥å…·ã€‚
    ä½¿ç”¨stackå°†è¿æ¥ç”Ÿå‘½å‘¨æœŸæ‰˜ç®¡ç»™ä¸Šå±‚
    """
    all_tools = []
    for conf in configs:
        print(f'ğŸ”Œ æ­£åœ¨è¿æ¥:{conf["name"]}...')
        # åˆå§‹åŒ– Client
        client = MCPClient(
            command=conf["command"],
            args=conf["args"],
            env=conf.get("env") # å¯é€‰å‚æ•°
        )
        # ğŸ”¥:enter_async_context æ›¿ä»£äº†async with ç¼©è¿›
        # è¿™æ ·æ— è®ºæœ‰å¤šå°‘ä¸ªMCPï¼Œä»£ç å±‚çº§éƒ½ä¸ä¼šå˜æ·±
        adapter = await stack.enter_async_context(LangChainMCPAdapter(client))
        # æ‰¹é‡è·å–ä¸€ä¸ªMCPä¸‹çš„æ‰€æœ‰å·¥å…·
        tools = await adapter.get_tools()
        print(f'    âœ…ï¸ è·å–å·¥å…·{[t.name for t in tools]}')
        all_tools.extend(tools)

    return all_tools

# ===ä¸»ç¨‹åº===
async def main():
    # ä½¿ç”¨ExitStackç»Ÿä¸€ç®¡ç†æ‰€æœ‰èµ„æºçš„å…³é—­
    async with AsyncExitStack() as stack:
        # A.æ’ä»¶(MCP)æ³¨å…¥é˜¶æ®µ -- å…è®¸ä¸ºç©º
        dynamic_tools = await load_mcp_tools(stack,MCP_SERVER_CONFIGS)

        # B.å›¾æ„å»ºé˜¶æ®µ
        app = build_graph(available_tools=dynamic_tools)

        # C.è¿è¡Œé˜¶æ®µ(æµå¼)
        query = "å¸®æˆ‘æŸ¥ä¸€ä¸‹æ­å·è¥¿æ¹–é™„è¿‘çš„é…’åº—"
        await run_agent_with_streaming(app,query)


if __name__ == '__main__':
    asyncio.run(main())